{
  
    
        "post0": {
            "title": "Title",
            "content": "Q.1 &amp; Q.2 Solution . The following block of code below utilises an image segmentation model to identify the various kinds of objects and walls in an image of a floor plan. . The model used is trained on CubiCasa dataset, and is a Google colabe running version of &#39;samples.ipynb&#39;, available at https://github.com/CubiCasa/CubiCasa5k . Downloading the repository . !git clone https://github.com/CubiCasa/CubiCasa5k.git . Cloning into &#39;CubiCasa5k&#39;... remote: Enumerating objects: 9, done. remote: Counting objects: 100% (9/9), done. remote: Compressing objects: 100% (9/9), done. remote: Total 81 (delta 4), reused 0 (delta 0), pack-reused 72 Unpacking objects: 100% (81/81), done. . import os . os.chdir(&#39;CubiCasa5k&#39;) . Instaling necessary libraries . !pip install -r requirements.txt . Collecting asn1crypto==0.24.0 Downloading https://files.pythonhosted.org/packages/ea/cd/35485615f45f30a510576f1a56d1e0a7ad7bd8ab5ed7cdc600ef7cd06222/asn1crypto-0.24.0-py2.py3-none-any.whl (101kB) |████████████████████████████████| 102kB 3.6MB/s Collecting attrs==19.1.0 Downloading https://files.pythonhosted.org/packages/23/96/d828354fa2dbdf216eaa7b7de0db692f12c234f7ef888cc14980ef40d1d2/attrs-19.1.0-py2.py3-none-any.whl Collecting backcall==0.1.0 Downloading https://files.pythonhosted.org/packages/84/71/c8ca4f5bb1e08401b916c68003acf0a0655df935d74d93bf3f3364b310e0/backcall-0.1.0.tar.gz Collecting bleach==3.1.0 Downloading https://files.pythonhosted.org/packages/ab/05/27e1466475e816d3001efb6e0a85a819be17411420494a1e602c36f8299d/bleach-3.1.0-py2.py3-none-any.whl (157kB) |████████████████████████████████| 163kB 6.7MB/s Collecting certifi==2018.10.15 Downloading https://files.pythonhosted.org/packages/56/9d/1d02dd80bc4cd955f98980f28c5ee2200e1209292d5f9e9cc8d030d18655/certifi-2018.10.15-py2.py3-none-any.whl (146kB) |████████████████████████████████| 153kB 6.2MB/s Collecting cffi==1.11.5 Downloading https://files.pythonhosted.org/packages/6d/c0/47db8f624f3e4e2f3f27be03a93379d1ba16a1450a7b1aacfa0366e2c0dd/cffi-1.11.5-cp36-cp36m-manylinux1_x86_64.whl (421kB) |████████████████████████████████| 430kB 8.8MB/s Requirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (3.0.4) Collecting cloudpickle==0.8.0 Downloading https://files.pythonhosted.org/packages/47/d5/efa7cacef5d3bdcd71d7053a698fb9b64a20fff5cb3c592efefa53ea5578/cloudpickle-0.8.0-py2.py3-none-any.whl Collecting cryptography==2.3.1 Downloading https://files.pythonhosted.org/packages/59/32/92cade62c645756a83598edf56289e9b19aae5370642a7ce690cd06bc72f/cryptography-2.3.1-cp34-abi3-manylinux1_x86_64.whl (2.1MB) |████████████████████████████████| 2.1MB 12.5MB/s Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.10.0) Collecting Cython==0.29.6 Downloading https://files.pythonhosted.org/packages/e1/fd/711507fa396064bf716493861d6955af45369d2c470548e34af20b79d4d4/Cython-0.29.6-cp36-cp36m-manylinux1_x86_64.whl (2.1MB) |████████████████████████████████| 2.1MB 53.9MB/s Collecting dask==1.1.4 Downloading https://files.pythonhosted.org/packages/b9/bc/0d747625c18397ed548c7890bf984a40d931b9ebac236c570a07565b0cc8/dask-1.1.4-py2.py3-none-any.whl (704kB) |████████████████████████████████| 706kB 60.3MB/s Collecting decorator==4.4.0 Downloading https://files.pythonhosted.org/packages/5f/88/0075e461560a1e750a0dcbf77f1d9de775028c37a19a346a6c565a257399/decorator-4.4.0-py2.py3-none-any.whl Collecting defusedxml==0.5.0 Downloading https://files.pythonhosted.org/packages/87/1c/17f3e3935a913dfe2a5ca85fa5ccbef366bfd82eb318b1f75dadbf0affca/defusedxml-0.5.0-py2.py3-none-any.whl Requirement already satisfied: entrypoints==0.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 15)) (0.3) Collecting graphviz==0.8.4 Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl Collecting h5py==2.8.0 Downloading https://files.pythonhosted.org/packages/8e/cb/726134109e7bd71d98d1fcc717ffe051767aac42ede0e7326fd1787e5d64/h5py-2.8.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB) |████████████████████████████████| 2.8MB 59.1MB/s Collecting h5py-cache==1.0 Downloading https://files.pythonhosted.org/packages/a8/3e/b8f1f444cfeced4f660ca66d51802e1d3e1815c368a832000bb26b68229c/h5py-cache-1.0.tar.gz Collecting idna==2.7 Downloading https://files.pythonhosted.org/packages/4b/2a/0276479a4b3caeb8a8c1af2f8e4355746a97fab05a372e4a2c6a6b876165/idna-2.7-py2.py3-none-any.whl (58kB) |████████████████████████████████| 61kB 10.1MB/s Collecting ipykernel==5.1.0 Downloading https://files.pythonhosted.org/packages/d8/b0/f0be5c5ab335196f5cce96e5b889a4fcf5bfe462eb0acc05cd7e2caf65eb/ipykernel-5.1.0-py3-none-any.whl (113kB) |████████████████████████████████| 122kB 57.4MB/s Collecting ipython==7.3.0 Downloading https://files.pythonhosted.org/packages/14/3b/3fcf422a99a04ee493e6a4fc3014e3c8ff484a7feed238fef68bdc285085/ipython-7.3.0-py3-none-any.whl (768kB) |████████████████████████████████| 778kB 58.6MB/s Requirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 22)) (0.2.0) Collecting jedi==0.13.3 Downloading https://files.pythonhosted.org/packages/25/2b/1f188901be099d52d7b06f4d3b7cb9f8f09692c50697b139eaf6fa2928d8/jedi-0.13.3-py2.py3-none-any.whl (178kB) |████████████████████████████████| 184kB 55.3MB/s Collecting Jinja2==2.10 Downloading https://files.pythonhosted.org/packages/7f/ff/ae64bacdfc95f27a016a7bed8e8686763ba4d277a78ca76f32659220a731/Jinja2-2.10-py2.py3-none-any.whl (126kB) |████████████████████████████████| 133kB 52.3MB/s Collecting joblib==0.13.2 Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB) |████████████████████████████████| 286kB 58.6MB/s Collecting jsonschema==3.0.1 Downloading https://files.pythonhosted.org/packages/aa/69/df679dfbdd051568b53c38ec8152a3ab6bc533434fc7ed11ab034bf5e82f/jsonschema-3.0.1-py2.py3-none-any.whl (54kB) |████████████████████████████████| 61kB 11.2MB/s Collecting jupyter-client==5.2.4 Downloading https://files.pythonhosted.org/packages/3b/c3/3043fe9ffd140d03c9d091a056794ccdc427c56ec19b8eea74f9ea0a498f/jupyter_client-5.2.4-py2.py3-none-any.whl (89kB) |████████████████████████████████| 92kB 12.2MB/s Collecting jupyter-core==4.4.0 Downloading https://files.pythonhosted.org/packages/1d/44/065d2d7bae7bebc06f1dd70d23c36da8c50c0f08b4236716743d706762a8/jupyter_core-4.4.0-py2.py3-none-any.whl (126kB) |████████████████████████████████| 133kB 66.9MB/s Collecting jupyterlab==0.35.4 Downloading https://files.pythonhosted.org/packages/45/77/40f2a382508d78a3f9fc59b98d67edd5b2999f8441d3945bfd37d2351a4d/jupyterlab-0.35.4-py3-none-any.whl (14.7MB) |████████████████████████████████| 14.7MB 181kB/s Collecting jupyterlab-server==0.2.0 Downloading https://files.pythonhosted.org/packages/78/77/e8a9c300afbe24aa46abaf1091d9e7b82328559e99cf2d601e858bcb3e1a/jupyterlab_server-0.2.0-py3-none-any.whl Collecting kiwisolver==1.0.1 Downloading https://files.pythonhosted.org/packages/69/a7/88719d132b18300b4369fbffa741841cfd36d1e637e1990f27929945b538/kiwisolver-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (949kB) |████████████████████████████████| 952kB 55.7MB/s Collecting lmdb==0.94 Downloading https://files.pythonhosted.org/packages/cb/31/5be8f436b56733d9e69c721c358502f4d77b627489a459978686be7db65f/lmdb-0.94.tar.gz (4.0MB) |████████████████████████████████| 4.0MB 57.1MB/s Requirement already satisfied: MarkupSafe==1.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 33)) (1.1.1) Collecting matplotlib==3.0.3 Downloading https://files.pythonhosted.org/packages/e9/69/f5e05f578585ed9935247be3788b374f90701296a70c8871bcd6d21edb00/matplotlib-3.0.3-cp36-cp36m-manylinux1_x86_64.whl (13.0MB) |████████████████████████████████| 13.0MB 123kB/s Requirement already satisfied: mistune==0.8.4 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 35)) (0.8.4) Collecting mkl-fft==1.0.6 Downloading https://files.pythonhosted.org/packages/f3/98/0783b1543ee73d47a258ebdffe002adcaabb18085653a6e83b42c6835c41/mkl_fft-1.0.6-cp36-cp36m-manylinux1_x86_64.whl (232kB) |████████████████████████████████| 235kB 54.9MB/s Collecting mkl-random==1.0.1 Downloading https://files.pythonhosted.org/packages/75/c0/7769ebbbcadf79613222a1e89d4278fb2d46bc98e554cd664a638a840747/mkl_random-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (393kB) |████████████████████████████████| 399kB 50.3MB/s Collecting nbconvert==5.4.1 Downloading https://files.pythonhosted.org/packages/b8/39/1e67fea74dc9577cc49f9863fe3ec824e525d1304ab6027d95a94cd586f5/nbconvert-5.4.1-py2.py3-none-any.whl (407kB) |████████████████████████████████| 409kB 52.5MB/s Collecting nbformat==4.4.0 Downloading https://files.pythonhosted.org/packages/da/27/9a654d2b6cc1eaa517d1c5a4405166c7f6d72f04f6e7eea41855fe808a46/nbformat-4.4.0-py2.py3-none-any.whl (155kB) |████████████████████████████████| 163kB 63.0MB/s Collecting networkx==2.2 Downloading https://files.pythonhosted.org/packages/f3/f4/7e20ef40b118478191cec0b58c3192f822cace858c19505c7670961b76b2/networkx-2.2.zip (1.7MB) |████████████████████████████████| 1.7MB 57.5MB/s Collecting notebook==5.7.6 Downloading https://files.pythonhosted.org/packages/0a/d8/4e9521354ed3d730ba6d8a5af440b66c73245ef46be706e51bead71afc21/notebook-5.7.6-py2.py3-none-any.whl (9.0MB) |████████████████████████████████| 9.0MB 17.3MB/s Collecting numpy==1.15.4 Downloading https://files.pythonhosted.org/packages/ff/7f/9d804d2348471c67a7d8b5f84f9bc59fd1cefa148986f2b74552f8573555/numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl (13.9MB) |████████████████████████████████| 13.9MB 243kB/s Collecting olefile==0.46 Downloading https://files.pythonhosted.org/packages/34/81/e1ac43c6b45b4c5f8d9352396a14144bba52c8fec72a80f425f6a4d653ad/olefile-0.46.zip (112kB) |████████████████████████████████| 112kB 63.1MB/s Collecting pandas==0.24.2 Downloading https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1MB) |████████████████████████████████| 10.1MB 30.7MB/s Requirement already satisfied: pandocfilters==1.4.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 45)) (1.4.2) Collecting parso==0.3.4 Downloading https://files.pythonhosted.org/packages/19/b1/522b2671cc6d134c9d3f5dfc0d02fee07cab848e908d03d2bffea78cca8f/parso-0.3.4-py2.py3-none-any.whl (93kB) |████████████████████████████████| 102kB 15.7MB/s Collecting pexpect==4.6.0 Downloading https://files.pythonhosted.org/packages/89/e6/b5a1de8b0cc4e07ca1b305a4fcc3f9806025c1b651ea302646341222f88b/pexpect-4.6.0-py2.py3-none-any.whl (57kB) |████████████████████████████████| 61kB 11.5MB/s Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 48)) (0.7.5) Collecting Pillow==5.4.1 Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB) |████████████████████████████████| 2.0MB 52.1MB/s Collecting prometheus-client==0.6.0 Downloading https://files.pythonhosted.org/packages/4c/bd/b42db3ec90ffc6be805aad09c1cea4bb13a620d0cd4b21aaa44d13541d71/prometheus_client-0.6.0.tar.gz Collecting prompt-toolkit==2.0.9 Downloading https://files.pythonhosted.org/packages/f7/a7/9b1dd14ef45345f186ef69d175bdd2491c40ab1dfa4b2b3e4352df719ed7/prompt_toolkit-2.0.9-py3-none-any.whl (337kB) |████████████████████████████████| 337kB 54.2MB/s Collecting protobuf==3.7.0 Downloading https://files.pythonhosted.org/packages/c5/60/ca38e967360212ddbb004141a70f5f6d47296e1fba37964d8ac6cb631921/protobuf-3.7.0-cp36-cp36m-manylinux1_x86_64.whl (1.2MB) |████████████████████████████████| 1.2MB 49.7MB/s Requirement already satisfied: ptyprocess==0.6.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 53)) (0.6.0) Collecting pycparser==2.19 Downloading https://files.pythonhosted.org/packages/68/9e/49196946aee219aead1290e00d1e7fdeab8567783e83e1b9ab5585e6206a/pycparser-2.19.tar.gz (158kB) |████████████████████████████████| 163kB 66.5MB/s Collecting Pygments==2.3.1 Downloading https://files.pythonhosted.org/packages/13/e5/6d710c9cf96c31ac82657bcfb441df328b22df8564d58d0c4cd62612674c/Pygments-2.3.1-py2.py3-none-any.whl (849kB) |████████████████████████████████| 849kB 46.6MB/s Collecting pyOpenSSL==18.0.0 Downloading https://files.pythonhosted.org/packages/96/af/9d29e6bd40823061aea2e0574ccb2fcf72bfd6130ce53d32773ec375458c/pyOpenSSL-18.0.0-py2.py3-none-any.whl (53kB) |████████████████████████████████| 61kB 11.4MB/s Collecting pyparsing==2.3.1 Downloading https://files.pythonhosted.org/packages/de/0a/001be530836743d8be6c2d85069f46fecf84ac6c18c7f5fb8125ee11d854/pyparsing-2.3.1-py2.py3-none-any.whl (61kB) |████████████████████████████████| 71kB 11.5MB/s Collecting pyrsistent==0.14.11 Downloading https://files.pythonhosted.org/packages/8c/46/4e93ab8a379d7efe93f20a0fb8a27bdfe88942cc954ab0210c3164e783e0/pyrsistent-0.14.11.tar.gz (104kB) |████████████████████████████████| 112kB 59.6MB/s Collecting PySocks==1.6.8 Downloading https://files.pythonhosted.org/packages/53/12/6bf1d764f128636cef7408e8156b7235b150ea31650d0260969215bb8e7d/PySocks-1.6.8.tar.gz (283kB) |████████████████████████████████| 286kB 54.7MB/s Collecting python-dateutil==2.8.0 Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB) |████████████████████████████████| 235kB 58.5MB/s Requirement already satisfied: pytz==2018.9 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 61)) (2018.9) Collecting PyWavelets==1.0.2 Downloading https://files.pythonhosted.org/packages/92/9a/2816f258df2e4e5885ebcb7695619c254f0d8f94f700c204c3eb77e8c0fd/PyWavelets-1.0.2-cp36-cp36m-manylinux1_x86_64.whl (4.4MB) |████████████████████████████████| 4.4MB 61.1MB/s Collecting pyzmq==17.1.2 Downloading https://files.pythonhosted.org/packages/48/93/59592cb294761aaa40589b544eaa5175446d687ff95beeeb666de60f3274/pyzmq-17.1.2-cp36-cp36m-manylinux1_x86_64.whl (998kB) |████████████████████████████████| 1.0MB 57.2MB/s Collecting requests==2.20.1 Downloading https://files.pythonhosted.org/packages/ff/17/5cbb026005115301a8fb2f9b0e3e8d32313142fe8b617070e7baad20554f/requests-2.20.1-py2.py3-none-any.whl (57kB) |████████████████████████████████| 61kB 11.0MB/s Collecting scikit-image==0.14.2 Downloading https://files.pythonhosted.org/packages/24/06/d560630eb9e36d90d69fe57d9ff762d8f501664ce478b8a0ae132b3c3008/scikit_image-0.14.2-cp36-cp36m-manylinux1_x86_64.whl (25.3MB) |████████████████████████████████| 25.3MB 130kB/s Collecting scipy==1.1.0 Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB) |████████████████████████████████| 31.2MB 85kB/s Requirement already satisfied: Send2Trash==1.5.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 67)) (1.5.0) Collecting Shapely==1.6.4.post2 Downloading https://files.pythonhosted.org/packages/38/b6/b53f19062afd49bb5abd049aeed36f13bf8d57ef8f3fa07a5203531a0252/Shapely-1.6.4.post2-cp36-cp36m-manylinux1_x86_64.whl (1.5MB) |████████████████████████████████| 1.5MB 59.8MB/s Collecting six==1.11.0 Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl Collecting svgpathtools==1.3.3 Downloading https://files.pythonhosted.org/packages/71/96/cc91050f3b53c2cea0eda18f371d0584e7f43713ce606738384e8001a877/svgpathtools-1.3.3-py2.py3-none-any.whl (50kB) |████████████████████████████████| 51kB 9.5MB/s Collecting svgwrite==1.2.1 Downloading https://files.pythonhosted.org/packages/87/ce/3259f75aebb12d8c7dd9e8c479ad4968db5ed18e03f24ee4f6be9d9aed23/svgwrite-1.2.1-py2.py3-none-any.whl (66kB) |████████████████████████████████| 71kB 12.2MB/s Collecting tensorboardX==1.6 Downloading https://files.pythonhosted.org/packages/5c/76/89dd44458eb976347e5a6e75eb79fecf8facd46c1ce259bad54e0044ea35/tensorboardX-1.6-py2.py3-none-any.whl (129kB) |████████████████████████████████| 133kB 64.4MB/s Collecting terminado==0.8.1 Downloading https://files.pythonhosted.org/packages/2e/20/a26211a24425923d46e1213b376a6ee60dc30bcdf1b0c345e2c3769deb1c/terminado-0.8.1-py2.py3-none-any.whl Collecting testpath==0.4.2 Downloading https://files.pythonhosted.org/packages/be/a4/162f9ebb6489421fe46dcca2ae420369edfee4b563c668d93cb4605d12ba/testpath-0.4.2-py2.py3-none-any.whl (163kB) |████████████████████████████████| 163kB 60.8MB/s Collecting toolz==0.9.0 Downloading https://files.pythonhosted.org/packages/14/d0/a73c15bbeda3d2e7b381a36afb0d9cd770a9f4adc5d1532691013ba881db/toolz-0.9.0.tar.gz (45kB) |████████████████████████████████| 51kB 9.0MB/s Collecting torch==1.0.0 Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB) |████████████████████████████████| 591.8MB 19kB/s Collecting torchfile==0.1.0 Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz Collecting torchnet==0.0.4 Downloading https://files.pythonhosted.org/packages/b7/b2/d7f70a85d3f6b0365517782632f150e3bbc2fb8e998cd69e27deba599aae/torchnet-0.0.4.tar.gz Collecting torchvision==0.2.1 Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB) |████████████████████████████████| 61kB 10.1MB/s Requirement already satisfied: tornado==5.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 80)) (5.1.1) Collecting tqdm==4.31.1 Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB) |████████████████████████████████| 51kB 8.7MB/s Collecting traitlets==4.3.2 Downloading https://files.pythonhosted.org/packages/93/d6/abcb22de61d78e2fc3959c964628a5771e47e7cc60d53e9342e21ed6cc9a/traitlets-4.3.2-py2.py3-none-any.whl (74kB) |████████████████████████████████| 81kB 9.9MB/s Collecting urllib3==1.24.1 Downloading https://files.pythonhosted.org/packages/62/00/ee1d7de624db8ba7090d1226aebefab96a2c71cd5cfa7629d6ad3f61b79e/urllib3-1.24.1-py2.py3-none-any.whl (118kB) |████████████████████████████████| 122kB 65.3MB/s Collecting visdom==0.1.8.5 Downloading https://files.pythonhosted.org/packages/c1/48/d90e1519768107811fd6e7760bea46fff9e9c9ffb490441684003ae634a9/visdom-0.1.8.5.tar.gz (248kB) |████████████████████████████████| 256kB 62.8MB/s Collecting wcwidth==0.1.7 Downloading https://files.pythonhosted.org/packages/7e/9f/526a6947247599b084ee5232e4f9190a38f398d7300d866af3ab571a5bfe/wcwidth-0.1.7-py2.py3-none-any.whl Requirement already satisfied: webencodings==0.5.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 86)) (0.5.1) Collecting websocket-client==0.54.0 Downloading https://files.pythonhosted.org/packages/26/2d/f749a5c82f6192d77ed061a38e02001afcba55fe8477336d26a950ab17ce/websocket_client-0.54.0-py2.py3-none-any.whl (200kB) |████████████████████████████████| 204kB 60.0MB/s Requirement already satisfied: setuptools&gt;=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython==7.3.0-&gt;-r requirements.txt (line 21)) (49.6.0) Collecting intel-numpy Downloading https://files.pythonhosted.org/packages/ef/b3/fb79b1f34dc83822ea4e57c9a889ee32a34087139c12c9f1c3473f060d4d/intel_numpy-1.15.1-cp36-cp36m-manylinux1_x86_64.whl (6.1MB) |████████████████████████████████| 6.1MB 10.4MB/s Requirement already satisfied: mkl in /usr/local/lib/python3.6/dist-packages (from intel-numpy-&gt;mkl-fft==1.0.6-&gt;-r requirements.txt (line 36)) (2019.0) Collecting tbb4py Downloading https://files.pythonhosted.org/packages/af/88/06532a4fb130ce4d1573a0b13ae3c58d689fe950e9806c507ba44d13ab17/tbb4py-2019.0-cp36-cp36m-manylinux1_x86_64.whl (225kB) |████████████████████████████████| 235kB 61.5MB/s Collecting icc-rt Downloading https://files.pythonhosted.org/packages/49/2d/3a308249f7e9d322a8858af3930670c8de7ebb131090a6e62473db844fdd/icc_rt-2020.0.133-py2.py3-none-manylinux1_x86_64.whl (11.2MB) |████████████████████████████████| 11.2MB 20.6MB/s Requirement already satisfied: intel-openmp in /usr/local/lib/python3.6/dist-packages (from mkl-&gt;intel-numpy-&gt;mkl-fft==1.0.6-&gt;-r requirements.txt (line 36)) (2020.0.133) Collecting tbb==2019.* Downloading https://files.pythonhosted.org/packages/28/53/8bf93994fd985ea08c1ef64c7ec94a433611c6f6af5e3ddcc8c49d83fd5c/tbb-2019.0-py2.py3-none-manylinux1_x86_64.whl (895kB) |████████████████████████████████| 901kB 49.8MB/s Building wheels for collected packages: backcall, h5py-cache, lmdb, networkx, olefile, prometheus-client, pycparser, pyrsistent, PySocks, toolz, torchfile, torchnet, visdom Building wheel for backcall (setup.py) ... done Created wheel for backcall: filename=backcall-0.1.0-cp36-none-any.whl size=10413 sha256=303b0ae57ae08a50a061e2f9f1720a5bc8ea4d6fae9065d7a9d60be39099b1d8 Stored in directory: /root/.cache/pip/wheels/98/b0/dd/29e28ff615af3dda4c67cab719dd51357597eabff926976b45 Building wheel for h5py-cache (setup.py) ... done Created wheel for h5py-cache: filename=h5py_cache-1.0-cp36-none-any.whl size=3408 sha256=103c1491a3d8e99bbaa540d9320fa02e0746684ab36d8ae337a528af4b01af9e Stored in directory: /root/.cache/pip/wheels/f0/ce/3e/40128ad3a26c4737100842671c7006428f83b328232c210569 Building wheel for lmdb (setup.py) ... done Created wheel for lmdb: filename=lmdb-0.94-cp36-cp36m-linux_x86_64.whl size=218578 sha256=a573d25c38c13fec423ba7b3a1e715d64410c7f6e9a9cbc273fb4538e185aa4a Stored in directory: /root/.cache/pip/wheels/57/40/51/3fe10a4a559a91352579a27cbcca490f279bacb54209713c4b Building wheel for networkx (setup.py) ... done Created wheel for networkx: filename=networkx-2.2-py2.py3-none-any.whl size=1527323 sha256=09036e8057fcce6fb45c7390cda3fea5cad627bcdd8ad4f30f854de09d402138 Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91 Building wheel for olefile (setup.py) ... done Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35415 sha256=825925df7de02535cf768bded8049c6b538fdd99a78b30466990427795332b57 Stored in directory: /root/.cache/pip/wheels/4b/f4/11/bc4166107c27f07fd7bba707ffcb439619197638a1ac986df3 Building wheel for prometheus-client (setup.py) ... done Created wheel for prometheus-client: filename=prometheus_client-0.6.0-cp36-none-any.whl size=39588 sha256=54723a5c0687ca569f6ca29b77858a1aae434540333a56802508e99e7f310ac8 Stored in directory: /root/.cache/pip/wheels/4b/04/b8/3709c73e7453f311ebd46ad581b89642543213f995e2659b9e Building wheel for pycparser (setup.py) ... done Created wheel for pycparser: filename=pycparser-2.19-py2.py3-none-any.whl size=111031 sha256=26278d1bc1ca6af4183fda013cd78e22ee77090cb3cb478c21bfff8281c9af65 Stored in directory: /root/.cache/pip/wheels/f2/9a/90/de94f8556265ddc9d9c8b271b0f63e57b26fb1d67a45564511 Building wheel for pyrsistent (setup.py) ... done Created wheel for pyrsistent: filename=pyrsistent-0.14.11-cp36-cp36m-linux_x86_64.whl size=95882 sha256=de0b885ba6c5cd7c1f3e03852d155777d841a612c4da479b6b55b6b1f68d39aa Stored in directory: /root/.cache/pip/wheels/83/59/9a/a037b9b3c3e93d9275ea0aff9d6064400f372879dfdab01afe Building wheel for PySocks (setup.py) ... done Created wheel for PySocks: filename=PySocks-1.6.8-cp36-none-any.whl size=12404 sha256=56854059526dee5bd225a782f7d2a20f4dafb3297e0e27d52ea8b01ebaa13f52 Stored in directory: /root/.cache/pip/wheels/22/5c/b5/12e0dfdfa85bea67b23628b6425fae715c687e947a45ee3df9 Building wheel for toolz (setup.py) ... done Created wheel for toolz: filename=toolz-0.9.0-cp36-none-any.whl size=53242 sha256=bb677e1d3db32a59d5ff7e974c15065c10e544e2b78cf0f73903961de13dfcbd Stored in directory: /root/.cache/pip/wheels/f4/0c/f6/ce6b2d1aa459ee97cc3c0f82236302bd62d89c86c700219463 Building wheel for torchfile (setup.py) ... done Created wheel for torchfile: filename=torchfile-0.1.0-cp36-none-any.whl size=5711 sha256=6628d26f246807b64396b2a104454073d3eb3c5884aee7fb3d295e60429f29cc Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814 Building wheel for torchnet (setup.py) ... done Created wheel for torchnet: filename=torchnet-0.0.4-cp36-none-any.whl size=29747 sha256=3616e56f32873357f3e13c3f4b91b0ab4075756ea451ce8b61a9fe25d8b3a7f2 Stored in directory: /root/.cache/pip/wheels/e1/03/fb/1c212c2f20905cdf97fe39022946cf16b8e66ed754a6663400 Building wheel for visdom (setup.py) ... done Created wheel for visdom: filename=visdom-0.1.8.5-cp36-none-any.whl size=228473 sha256=f2e50908ccf388fe911c116139d579ac58e6a0718ed0415430e458dc950e2a33 Stored in directory: /root/.cache/pip/wheels/fb/ef/d8/ad95fbafb505c507b476c4e907af570d2dd41ae725cdc9b391 Successfully built backcall h5py-cache lmdb networkx olefile prometheus-client pycparser pyrsistent PySocks toolz torchfile torchnet visdom ERROR: xarray 0.15.1 has requirement pandas&gt;=0.25, but you&#39;ll have pandas 0.24.2 which is incompatible. ERROR: umap-learn 0.4.6 has requirement numpy&gt;=1.17, but you&#39;ll have numpy 1.15.4 which is incompatible. ERROR: umap-learn 0.4.6 has requirement scipy&gt;=1.3.1, but you&#39;ll have scipy 1.1.0 which is incompatible. ERROR: tensorflow 2.3.0 has requirement h5py&lt;2.11.0,&gt;=2.10.0, but you&#39;ll have h5py 2.8.0 which is incompatible. ERROR: tensorflow 2.3.0 has requirement numpy&lt;1.19.0,&gt;=1.16.0, but you&#39;ll have numpy 1.15.4 which is incompatible. ERROR: tensorflow 2.3.0 has requirement protobuf&gt;=3.9.2, but you&#39;ll have protobuf 3.7.0 which is incompatible. ERROR: tensorflow 2.3.0 has requirement scipy==1.4.1, but you&#39;ll have scipy 1.1.0 which is incompatible. ERROR: tensorflow 2.3.0 has requirement six&gt;=1.12.0, but you&#39;ll have six 1.11.0 which is incompatible. ERROR: tensorflow-probability 0.11.0 has requirement cloudpickle==1.3, but you&#39;ll have cloudpickle 0.8.0 which is incompatible. ERROR: tensorflow-hub 0.9.0 has requirement protobuf&gt;=3.8.0, but you&#39;ll have protobuf 3.7.0 which is incompatible. ERROR: tensorflow-hub 0.9.0 has requirement six&gt;=1.12.0, but you&#39;ll have six 1.11.0 which is incompatible. ERROR: tensorboard 2.3.0 has requirement requests&lt;3,&gt;=2.21.0, but you&#39;ll have requests 2.20.1 which is incompatible. ERROR: spacy 2.2.4 has requirement tqdm&lt;5.0.0,&gt;=4.38.0, but you&#39;ll have tqdm 4.31.1 which is incompatible. ERROR: rpy2 3.2.7 has requirement cffi&gt;=1.13.1, but you&#39;ll have cffi 1.11.5 which is incompatible. ERROR: plotnine 0.6.0 has requirement matplotlib&gt;=3.1.1, but you&#39;ll have matplotlib 3.0.3 which is incompatible. ERROR: plotnine 0.6.0 has requirement numpy&gt;=1.16.0, but you&#39;ll have numpy 1.15.4 which is incompatible. ERROR: plotnine 0.6.0 has requirement pandas&gt;=0.25.0, but you&#39;ll have pandas 0.24.2 which is incompatible. ERROR: plotnine 0.6.0 has requirement scipy&gt;=1.2.0, but you&#39;ll have scipy 1.1.0 which is incompatible. ERROR: mizani 0.6.0 has requirement matplotlib&gt;=3.1.1, but you&#39;ll have matplotlib 3.0.3 which is incompatible. ERROR: mizani 0.6.0 has requirement pandas&gt;=0.25.0, but you&#39;ll have pandas 0.24.2 which is incompatible. ERROR: jupyter-console 5.2.0 has requirement prompt-toolkit&lt;2.0.0,&gt;=1.0.0, but you&#39;ll have prompt-toolkit 2.0.9 which is incompatible. ERROR: gym 0.17.2 has requirement cloudpickle&lt;1.4.0,&gt;=1.2.0, but you&#39;ll have cloudpickle 0.8.0 which is incompatible. ERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you&#39;ll have ipykernel 5.1.0 which is incompatible. ERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you&#39;ll have ipython 7.3.0 which is incompatible. ERROR: google-colab 1.0.0 has requirement notebook~=5.3.0; python_version &gt;= &#34;3.0&#34;, but you&#39;ll have notebook 5.7.6 which is incompatible. ERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version &gt;= &#34;3.0&#34;, but you&#39;ll have pandas 0.24.2 which is incompatible. ERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you&#39;ll have requests 2.20.1 which is incompatible. ERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you&#39;ll have six 1.11.0 which is incompatible. ERROR: flask 1.1.2 has requirement Jinja2&gt;=2.10.1, but you&#39;ll have jinja2 2.10 which is incompatible. ERROR: dm-tree 0.1.5 has requirement six&gt;=1.12.0, but you&#39;ll have six 1.11.0 which is incompatible. ERROR: datascience 0.10.6 has requirement folium==0.2.1, but you&#39;ll have folium 0.8.3 which is incompatible. ERROR: astropy 4.0.1.post1 has requirement numpy&gt;=1.16, but you&#39;ll have numpy 1.15.4 which is incompatible. ERROR: albumentations 0.1.12 has requirement imgaug&lt;0.2.7,&gt;=0.2.5, but you&#39;ll have imgaug 0.2.9 which is incompatible. ERROR: mkl-random 1.0.1 has requirement intel-numpy&lt;1.15,&gt;=1.14, but you&#39;ll have intel-numpy 1.15.1 which is incompatible. Installing collected packages: asn1crypto, attrs, backcall, six, bleach, certifi, pycparser, cffi, cloudpickle, idna, cryptography, Cython, dask, decorator, defusedxml, graphviz, numpy, h5py, h5py-cache, wcwidth, prompt-toolkit, Pygments, pexpect, parso, jedi, traitlets, ipython, python-dateutil, pyzmq, jupyter-core, jupyter-client, ipykernel, Jinja2, joblib, pyrsistent, jsonschema, nbformat, terminado, prometheus-client, testpath, nbconvert, notebook, jupyterlab-server, jupyterlab, kiwisolver, lmdb, pyparsing, matplotlib, tbb, tbb4py, icc-rt, mkl-random, intel-numpy, mkl-fft, networkx, olefile, pandas, Pillow, protobuf, pyOpenSSL, PySocks, PyWavelets, urllib3, requests, scipy, scikit-image, Shapely, svgwrite, svgpathtools, tensorboardX, toolz, torch, torchfile, websocket-client, visdom, torchnet, torchvision, tqdm Found existing installation: attrs 20.1.0 Uninstalling attrs-20.1.0: Successfully uninstalled attrs-20.1.0 Found existing installation: backcall 0.2.0 Uninstalling backcall-0.2.0: Successfully uninstalled backcall-0.2.0 Found existing installation: six 1.15.0 Uninstalling six-1.15.0: Successfully uninstalled six-1.15.0 Found existing installation: bleach 3.1.5 Uninstalling bleach-3.1.5: Successfully uninstalled bleach-3.1.5 Found existing installation: certifi 2020.6.20 Uninstalling certifi-2020.6.20: Successfully uninstalled certifi-2020.6.20 Found existing installation: pycparser 2.20 Uninstalling pycparser-2.20: Successfully uninstalled pycparser-2.20 Found existing installation: cffi 1.14.2 Uninstalling cffi-1.14.2: Successfully uninstalled cffi-1.14.2 Found existing installation: cloudpickle 1.3.0 Uninstalling cloudpickle-1.3.0: Successfully uninstalled cloudpickle-1.3.0 Found existing installation: idna 2.10 Uninstalling idna-2.10: Successfully uninstalled idna-2.10 Found existing installation: Cython 0.29.21 Uninstalling Cython-0.29.21: Successfully uninstalled Cython-0.29.21 Found existing installation: dask 2.12.0 Uninstalling dask-2.12.0: Successfully uninstalled dask-2.12.0 Found existing installation: decorator 4.4.2 Uninstalling decorator-4.4.2: Successfully uninstalled decorator-4.4.2 Found existing installation: defusedxml 0.6.0 Uninstalling defusedxml-0.6.0: Successfully uninstalled defusedxml-0.6.0 Found existing installation: graphviz 0.10.1 Uninstalling graphviz-0.10.1: Successfully uninstalled graphviz-0.10.1 Found existing installation: numpy 1.18.5 Uninstalling numpy-1.18.5: Successfully uninstalled numpy-1.18.5 Found existing installation: h5py 2.10.0 Uninstalling h5py-2.10.0: Successfully uninstalled h5py-2.10.0 Found existing installation: wcwidth 0.2.5 Uninstalling wcwidth-0.2.5: Successfully uninstalled wcwidth-0.2.5 Found existing installation: prompt-toolkit 1.0.18 Uninstalling prompt-toolkit-1.0.18: Successfully uninstalled prompt-toolkit-1.0.18 Found existing installation: Pygments 2.1.3 Uninstalling Pygments-2.1.3: Successfully uninstalled Pygments-2.1.3 Found existing installation: pexpect 4.8.0 Uninstalling pexpect-4.8.0: Successfully uninstalled pexpect-4.8.0 Found existing installation: parso 0.7.1 Uninstalling parso-0.7.1: Successfully uninstalled parso-0.7.1 Found existing installation: jedi 0.17.2 Uninstalling jedi-0.17.2: Successfully uninstalled jedi-0.17.2 Found existing installation: traitlets 4.3.3 Uninstalling traitlets-4.3.3: Successfully uninstalled traitlets-4.3.3 Found existing installation: ipython 5.5.0 Uninstalling ipython-5.5.0: Successfully uninstalled ipython-5.5.0 Found existing installation: python-dateutil 2.8.1 Uninstalling python-dateutil-2.8.1: Successfully uninstalled python-dateutil-2.8.1 Found existing installation: pyzmq 19.0.2 Uninstalling pyzmq-19.0.2: Successfully uninstalled pyzmq-19.0.2 Found existing installation: jupyter-core 4.6.3 Uninstalling jupyter-core-4.6.3: Successfully uninstalled jupyter-core-4.6.3 Found existing installation: jupyter-client 5.3.5 Uninstalling jupyter-client-5.3.5: Successfully uninstalled jupyter-client-5.3.5 Found existing installation: ipykernel 4.10.1 Uninstalling ipykernel-4.10.1: Successfully uninstalled ipykernel-4.10.1 Found existing installation: Jinja2 2.11.2 Uninstalling Jinja2-2.11.2: Successfully uninstalled Jinja2-2.11.2 Found existing installation: joblib 0.16.0 Uninstalling joblib-0.16.0: Successfully uninstalled joblib-0.16.0 Found existing installation: pyrsistent 0.16.0 Uninstalling pyrsistent-0.16.0: Successfully uninstalled pyrsistent-0.16.0 Found existing installation: jsonschema 2.6.0 Uninstalling jsonschema-2.6.0: Successfully uninstalled jsonschema-2.6.0 Found existing installation: nbformat 5.0.7 Uninstalling nbformat-5.0.7: Successfully uninstalled nbformat-5.0.7 Found existing installation: terminado 0.8.3 Uninstalling terminado-0.8.3: Successfully uninstalled terminado-0.8.3 Found existing installation: prometheus-client 0.8.0 Uninstalling prometheus-client-0.8.0: Successfully uninstalled prometheus-client-0.8.0 Found existing installation: testpath 0.4.4 Uninstalling testpath-0.4.4: Successfully uninstalled testpath-0.4.4 Found existing installation: nbconvert 5.6.1 Uninstalling nbconvert-5.6.1: Successfully uninstalled nbconvert-5.6.1 Found existing installation: notebook 5.3.1 Uninstalling notebook-5.3.1: Successfully uninstalled notebook-5.3.1 Found existing installation: kiwisolver 1.2.0 Uninstalling kiwisolver-1.2.0: Successfully uninstalled kiwisolver-1.2.0 Found existing installation: lmdb 0.99 Uninstalling lmdb-0.99: Successfully uninstalled lmdb-0.99 Found existing installation: pyparsing 2.4.7 Uninstalling pyparsing-2.4.7: Successfully uninstalled pyparsing-2.4.7 Found existing installation: matplotlib 3.2.2 Uninstalling matplotlib-3.2.2: Successfully uninstalled matplotlib-3.2.2 Found existing installation: networkx 2.5 Uninstalling networkx-2.5: Successfully uninstalled networkx-2.5 Found existing installation: pandas 1.0.5 Uninstalling pandas-1.0.5: Successfully uninstalled pandas-1.0.5 Found existing installation: Pillow 7.0.0 Uninstalling Pillow-7.0.0: Successfully uninstalled Pillow-7.0.0 Found existing installation: protobuf 3.12.4 Uninstalling protobuf-3.12.4: Successfully uninstalled protobuf-3.12.4 Found existing installation: PySocks 1.7.1 Uninstalling PySocks-1.7.1: Successfully uninstalled PySocks-1.7.1 Found existing installation: PyWavelets 1.1.1 Uninstalling PyWavelets-1.1.1: Successfully uninstalled PyWavelets-1.1.1 Found existing installation: urllib3 1.24.3 Uninstalling urllib3-1.24.3: Successfully uninstalled urllib3-1.24.3 Found existing installation: requests 2.23.0 Uninstalling requests-2.23.0: Successfully uninstalled requests-2.23.0 Found existing installation: scipy 1.4.1 Uninstalling scipy-1.4.1: Successfully uninstalled scipy-1.4.1 Found existing installation: scikit-image 0.16.2 Uninstalling scikit-image-0.16.2: Successfully uninstalled scikit-image-0.16.2 Found existing installation: Shapely 1.7.1 Uninstalling Shapely-1.7.1: Successfully uninstalled Shapely-1.7.1 Found existing installation: toolz 0.10.0 Uninstalling toolz-0.10.0: Successfully uninstalled toolz-0.10.0 Found existing installation: torch 1.6.0+cu101 Uninstalling torch-1.6.0+cu101: Successfully uninstalled torch-1.6.0+cu101 Found existing installation: torchvision 0.7.0+cu101 Uninstalling torchvision-0.7.0+cu101: Successfully uninstalled torchvision-0.7.0+cu101 Found existing installation: tqdm 4.41.1 Uninstalling tqdm-4.41.1: Successfully uninstalled tqdm-4.41.1 Successfully installed Cython-0.29.6 Jinja2-2.10 Pillow-5.4.1 PySocks-1.6.8 PyWavelets-1.0.2 Pygments-2.3.1 Shapely-1.6.4.post2 asn1crypto-0.24.0 attrs-19.1.0 backcall-0.1.0 bleach-3.1.0 certifi-2018.10.15 cffi-1.11.5 cloudpickle-0.8.0 cryptography-2.3.1 dask-1.1.4 decorator-4.4.0 defusedxml-0.5.0 graphviz-0.8.4 h5py-2.8.0 h5py-cache-1.0 icc-rt-2020.0.133 idna-2.7 intel-numpy-1.15.1 ipykernel-5.1.0 ipython-7.3.0 jedi-0.13.3 joblib-0.13.2 jsonschema-3.0.1 jupyter-client-5.2.4 jupyter-core-4.4.0 jupyterlab-0.35.4 jupyterlab-server-0.2.0 kiwisolver-1.0.1 lmdb-0.94 matplotlib-3.0.3 mkl-fft-1.0.6 mkl-random-1.0.1 nbconvert-5.4.1 nbformat-4.4.0 networkx-2.2 notebook-5.7.6 numpy-1.15.4 olefile-0.46 pandas-0.24.2 parso-0.3.4 pexpect-4.6.0 prometheus-client-0.6.0 prompt-toolkit-2.0.9 protobuf-3.7.0 pyOpenSSL-18.0.0 pycparser-2.19 pyparsing-2.3.1 pyrsistent-0.14.11 python-dateutil-2.8.0 pyzmq-17.1.2 requests-2.20.1 scikit-image-0.14.2 scipy-1.1.0 six-1.11.0 svgpathtools-1.3.3 svgwrite-1.2.1 tbb-2019.0 tbb4py-2019.0 tensorboardX-1.6 terminado-0.8.1 testpath-0.4.2 toolz-0.9.0 torch-1.0.0 torchfile-0.1.0 torchnet-0.0.4 torchvision-0.2.1 tqdm-4.31.1 traitlets-4.3.2 urllib3-1.24.1 visdom-0.1.8.5 wcwidth-0.1.7 websocket-client-0.54.0 . Downloading a bunch of images of floorplan images, to demonstrate the performance of model on them. This command below downloads a mini sample of the validation dataset, part of the CubiCasa Dataset. The validation dataset was not used to train this model. The minisample is hosted on my Google Drive and consists of 6 random floorplans from the validation dataset. . !wget --no-check-certificate &#39;https://docs.google.com/uc?export=download&amp;id=13x_D3GRdxurKFT8spZIOCn3rqZobFFHy&#39; -O data.zip . --2020-09-09 18:47:49-- https://docs.google.com/uc?export=download&amp;id=13x_D3GRdxurKFT8spZIOCn3rqZobFFHy Resolving docs.google.com (docs.google.com)... 173.194.203.138, 173.194.203.100, 173.194.203.101, ... Connecting to docs.google.com (docs.google.com)|173.194.203.138|:443... connected. HTTP request sent, awaiting response... 302 Moved Temporarily Location: https://doc-10-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/hufrouufthlnroaijjf72qcst7rl5hh2/1599677250000/17449735085288012097/*/13x_D3GRdxurKFT8spZIOCn3rqZobFFHy?e=download [following] Warning: wildcards not supported in HTTP. --2020-09-09 18:47:51-- https://doc-10-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/hufrouufthlnroaijjf72qcst7rl5hh2/1599677250000/17449735085288012097/*/13x_D3GRdxurKFT8spZIOCn3rqZobFFHy?e=download Resolving doc-10-ak-docs.googleusercontent.com (doc-10-ak-docs.googleusercontent.com)... 74.125.142.132, 2607:f8b0:400e:c08::84 Connecting to doc-10-ak-docs.googleusercontent.com (doc-10-ak-docs.googleusercontent.com)|74.125.142.132|:443... connected. HTTP request sent, awaiting response... 200 OK Length: unspecified [application/x-zip-compressed] Saving to: ‘data.zip’ data.zip [ &lt;=&gt; ] 3.44M --.-KB/s in 0.02s 2020-09-09 18:47:51 (207 MB/s) - ‘data.zip’ saved [3604165] . !unzip data.zip . Archive: data.zip creating: data/cubicasa5k/ creating: data/cubicasa5k/high_quality_architectural/ creating: data/cubicasa5k/high_quality_architectural/1191/ inflating: data/cubicasa5k/high_quality_architectural/1191/F1_original.png inflating: data/cubicasa5k/high_quality_architectural/1191/F1_scaled.png inflating: data/cubicasa5k/high_quality_architectural/1191/model.svg creating: data/cubicasa5k/high_quality_architectural/22/ inflating: data/cubicasa5k/high_quality_architectural/22/F1_original.png inflating: data/cubicasa5k/high_quality_architectural/22/F1_scaled.png inflating: data/cubicasa5k/high_quality_architectural/22/model.svg creating: data/cubicasa5k/high_quality_architectural/2207/ inflating: data/cubicasa5k/high_quality_architectural/2207/F1_original.png inflating: data/cubicasa5k/high_quality_architectural/2207/F1_scaled.png inflating: data/cubicasa5k/high_quality_architectural/2207/model.svg creating: data/cubicasa5k/high_quality_architectural/2504/ inflating: data/cubicasa5k/high_quality_architectural/2504/F1_original.png inflating: data/cubicasa5k/high_quality_architectural/2504/F1_scaled.png inflating: data/cubicasa5k/high_quality_architectural/2504/model.svg creating: data/cubicasa5k/high_quality_architectural/2530/ inflating: data/cubicasa5k/high_quality_architectural/2530/F1_original.png inflating: data/cubicasa5k/high_quality_architectural/2530/F1_scaled.png inflating: data/cubicasa5k/high_quality_architectural/2530/model.svg creating: data/cubicasa5k/high_quality_architectural/2536/ inflating: data/cubicasa5k/high_quality_architectural/2536/F1_original.png inflating: data/cubicasa5k/high_quality_architectural/2536/F1_scaled.png inflating: data/cubicasa5k/high_quality_architectural/2536/model.svg inflating: data/cubicasa5k/test.txt . Downloading the pretrained model made available along with the forementioned repository . !wget --load-cookies /tmp/cookies.txt &quot;https://docs.google.com/uc?export=download&amp;confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate &#39;https://docs.google.com/uc?export=download&amp;id=1gRB7ez1e4H7a9Y09lLqRuna0luZO5VRK&#39; -O- | sed -rn &#39;s/.*confirm=([0-9A-Za-z_]+).*/ 1 n/p&#39;)&amp;id=1gRB7ez1e4H7a9Y09lLqRuna0luZO5VRK&quot; -O t.pkl &amp;&amp; rm -rf /tmp/cookies.txt . --2020-09-09 18:47:59-- https://docs.google.com/uc?export=download&amp;confirm=WrFw&amp;id=1gRB7ez1e4H7a9Y09lLqRuna0luZO5VRK Resolving docs.google.com (docs.google.com)... 74.125.195.100, 74.125.195.101, 74.125.195.139, ... Connecting to docs.google.com (docs.google.com)|74.125.195.100|:443... connected. HTTP request sent, awaiting response... 302 Moved Temporarily Location: https://doc-0c-5g-docs.googleusercontent.com/docs/securesc/1mk3lgevfqu89j4jah4er61kt6lbgpni/deic2a3lti08ridlpnnjt8pv14ldr4v1/1599677250000/05431039146205173256/09396649492801234763Z/1gRB7ez1e4H7a9Y09lLqRuna0luZO5VRK?e=download [following] --2020-09-09 18:47:59-- https://doc-0c-5g-docs.googleusercontent.com/docs/securesc/1mk3lgevfqu89j4jah4er61kt6lbgpni/deic2a3lti08ridlpnnjt8pv14ldr4v1/1599677250000/05431039146205173256/09396649492801234763Z/1gRB7ez1e4H7a9Y09lLqRuna0luZO5VRK?e=download Resolving doc-0c-5g-docs.googleusercontent.com (doc-0c-5g-docs.googleusercontent.com)... 74.125.142.132, 2607:f8b0:400e:c08::84 Connecting to doc-0c-5g-docs.googleusercontent.com (doc-0c-5g-docs.googleusercontent.com)|74.125.142.132|:443... connected. HTTP request sent, awaiting response... 302 Found Location: https://docs.google.com/nonceSigner?nonce=rvsfp2pjlbt3k&amp;continue=https://doc-0c-5g-docs.googleusercontent.com/docs/securesc/1mk3lgevfqu89j4jah4er61kt6lbgpni/deic2a3lti08ridlpnnjt8pv14ldr4v1/1599677250000/05431039146205173256/09396649492801234763Z/1gRB7ez1e4H7a9Y09lLqRuna0luZO5VRK?e%3Ddownload&amp;hash=lqgmbsqrt1ed4f0pt1u6hb8o9afgbbdb [following] --2020-09-09 18:47:59-- https://docs.google.com/nonceSigner?nonce=rvsfp2pjlbt3k&amp;continue=https://doc-0c-5g-docs.googleusercontent.com/docs/securesc/1mk3lgevfqu89j4jah4er61kt6lbgpni/deic2a3lti08ridlpnnjt8pv14ldr4v1/1599677250000/05431039146205173256/09396649492801234763Z/1gRB7ez1e4H7a9Y09lLqRuna0luZO5VRK?e%3Ddownload&amp;hash=lqgmbsqrt1ed4f0pt1u6hb8o9afgbbdb Connecting to docs.google.com (docs.google.com)|74.125.195.100|:443... connected. HTTP request sent, awaiting response... 302 Found Location: https://doc-0c-5g-docs.googleusercontent.com/docs/securesc/1mk3lgevfqu89j4jah4er61kt6lbgpni/deic2a3lti08ridlpnnjt8pv14ldr4v1/1599677250000/05431039146205173256/09396649492801234763Z/1gRB7ez1e4H7a9Y09lLqRuna0luZO5VRK?e=download&amp;nonce=rvsfp2pjlbt3k&amp;user=09396649492801234763Z&amp;hash=dhjk77aafeup6e0e0e1aa77a09hkau29 [following] --2020-09-09 18:47:59-- https://doc-0c-5g-docs.googleusercontent.com/docs/securesc/1mk3lgevfqu89j4jah4er61kt6lbgpni/deic2a3lti08ridlpnnjt8pv14ldr4v1/1599677250000/05431039146205173256/09396649492801234763Z/1gRB7ez1e4H7a9Y09lLqRuna0luZO5VRK?e=download&amp;nonce=rvsfp2pjlbt3k&amp;user=09396649492801234763Z&amp;hash=dhjk77aafeup6e0e0e1aa77a09hkau29 Connecting to doc-0c-5g-docs.googleusercontent.com (doc-0c-5g-docs.googleusercontent.com)|74.125.142.132|:443... connected. HTTP request sent, awaiting response... 200 OK Length: unspecified [application/octet-stream] Saving to: ‘t.pkl’ t.pkl [ &lt;=&gt; ] 198.98M 124MB/s in 1.6s 2020-09-09 18:48:01 (124 MB/s) - ‘t.pkl’ saved [208651193] . %matplotlib inline from skimage import transform import numpy as np import matplotlib.pyplot as plt import matplotlib.image as mpimg import torch import torch.nn.functional as F from torch.utils.data import DataLoader from floortrans.models import get_model from floortrans.loaders import FloorplanSVG, DictToTensor, Compose, RotateNTurns from floortrans.plotting import segmentation_plot, polygons_to_image, draw_junction_from_dict, discrete_cmap discrete_cmap() from floortrans.post_prosessing import split_prediction, get_polygons, split_validation from mpl_toolkits.axes_grid1 import AxesGrid rot = RotateNTurns() room_classes = [&quot;Background&quot;, &quot;Outdoor&quot;, &quot;Wall&quot;, &quot;Kitchen&quot;, &quot;Living Room&quot; ,&quot;Bed Room&quot;, &quot;Bath&quot;, &quot;Entry&quot;, &quot;Railing&quot;, &quot;Storage&quot;, &quot;Garage&quot;, &quot;Undefined&quot;] icon_classes = [&quot;No Icon&quot;, &quot;Window&quot;, &quot;Door&quot;, &quot;Closet&quot;, &quot;Electrical Applience&quot; ,&quot;Toilet&quot;, &quot;Sink&quot;, &quot;Sauna Bench&quot;, &quot;Fire Place&quot;, &quot;Bathtub&quot;, &quot;Chimney&quot;] data_folder = &#39;data/cubicasa5k/&#39; data_file = &#39;test.txt&#39; . normal_set = FloorplanSVG(data_folder, data_file, format=&#39;txt&#39;, original_size=True) data_loader = DataLoader(normal_set, batch_size=1, num_workers=0) data_iter = iter(data_loader) # Setup Model model = get_model(&#39;hg_furukawa_original&#39;, 51) n_classes = 44 split = [21, 12, 11] model.conv4_ = torch.nn.Conv2d(256, n_classes, bias=True, kernel_size=1) model.upsample = torch.nn.ConvTranspose2d(n_classes, n_classes, kernel_size=4, stride=4) . checkpoint = torch.load(&#39;t.pkl&#39;) model.load_state_dict(checkpoint[&#39;model_state&#39;]) model.eval() model.cuda() print(&quot;Model loaded.&quot;) . Model loaded. . The following code block picks the first floor plan image from the downloaded mini sample and displays it. . To view and run the model on the next image, run all the code from this point onwards again, once the below code block is run. The below code blocks iterates in the 6 downloaded images. . val = next(data_iter) junctions = val[&#39;heatmaps&#39;] folder = val[&#39;folder&#39;][0] image = val[&#39;image&#39;].cuda() label = val[&#39;label&#39;] np_img = np.moveaxis(image[0].cpu().data.numpy(), 0, -1) / 2 + 0.5 plt.figure(figsize=(10,10)) plt.title(&#39;Source Image&#39;, fontsize=20) plt.axis(&#39;off&#39;) plt.imshow(np_img) plt.show() . The SVG floorplan . Parsed labels . The below code block displays the labels of various objects as labelled in the dataset. The various kinds of objects are represented by different colours in at their associated positions in the original floorplan image. . label_np = label.data.numpy()[0] plt.figure(figsize=(10,10)) ax = plt.subplot(1, 1, 1) plt.title(&#39;Rooms and walls&#39;, fontsize=20) ax.axis(&#39;off&#39;) n_rooms = 12 rseg = ax.imshow(label_np[0], cmap=&#39;rooms&#39;, vmin=0, vmax=n_rooms-0.1) cbar = plt.colorbar(rseg, ticks=np.arange(n_rooms) + 0.5, fraction=0.046, pad=0.01) cbar.ax.set_yticklabels(room_classes, fontsize=20) plt.show() plt.figure(figsize=(10,10)) ax = plt.subplot(1, 1, 1) plt.title(&#39;Icons&#39;, fontsize=20) ax.axis(&#39;off&#39;) n_icons = 11 iseg = ax.imshow(label_np[1], cmap=&#39;icons&#39;, vmin=0, vmax=n_icons-0.1) cbar = plt.colorbar(iseg, ticks=np.arange(n_icons) + 0.5, fraction=0.046, pad=0.01) cbar.ax.set_yticklabels(icon_classes, fontsize=20) plt.show() plt.figure(figsize=(10,10)) ax = plt.subplot(1, 1, 1) plt.title(&#39;Wall junctions, Icon corners and opening end points&#39;, fontsize=20) ax.axis(&#39;off&#39;) ax.imshow(np_img) h, w, _ = np_img.shape draw_junction_from_dict(junctions, w, h, size=0.3, fontsize=10) plt.show() . Networks prediction for the segmentation . Running the model on given floorplan image . The below code block shows the unprocessed predictions of the model on the image. . The numpy array &#39;rooms_pred&#39; contains the prediction of architectural elements. The numpy array &#39;icons_pred&#39; contains the prediction of objects in the floor plan. . with torch.no_grad(): height = label_np.shape[1] width = label_np.shape[2] img_size = (height, width) rotations = [(0, 0), (1, -1), (2, 2), (-1, 1)] pred_count = len(rotations) prediction = torch.zeros([pred_count, n_classes, height, width]) for i, r in enumerate(rotations): forward, back = r # We rotate first the image rot_image = rot(image, &#39;tensor&#39;, forward) pred = model(rot_image) # We rotate prediction back pred = rot(pred, &#39;tensor&#39;, back) # We fix heatmaps pred = rot(pred, &#39;points&#39;, back) # We make sure the size is correct pred = F.interpolate(pred, size=(height, width), mode=&#39;bilinear&#39;, align_corners=True) # We add the prediction to output prediction[i] = pred[0] prediction = torch.mean(prediction, 0, True) rooms_label = label_np[0] icons_label = label_np[1] rooms_pred = F.softmax(prediction[0, 21:21+12], 0).cpu().data.numpy() rooms_pred = np.argmax(rooms_pred, axis=0) icons_pred = F.softmax(prediction[0, 21+12:], 0).cpu().data.numpy() icons_pred = np.argmax(icons_pred, axis=0) plt.figure(figsize=(12,12)) ax = plt.subplot(1, 1, 1) ax.axis(&#39;off&#39;) rseg = ax.imshow(rooms_pred, cmap=&#39;rooms&#39;, vmin=0, vmax=n_rooms-0.1) cbar = plt.colorbar(rseg, ticks=np.arange(n_rooms) + 0.5, fraction=0.046, pad=0.01) cbar.ax.set_yticklabels(room_classes, fontsize=20) plt.show() plt.figure(figsize=(12,12)) ax = plt.subplot(1, 1, 1) ax.axis(&#39;off&#39;) iseg = ax.imshow(icons_pred, cmap=&#39;icons&#39;, vmin=0, vmax=n_icons-0.1) cbar = plt.colorbar(iseg, ticks=np.arange(n_icons) + 0.5, fraction=0.046, pad=0.01) cbar.ax.set_yticklabels(icon_classes, fontsize=20) plt.show() . Post-processed polygons . Below code block displays the final processed results of model&#39;s predictions. The location of each object and walls is clearly marked with distinct values in numpy arrays. . &#39;pol_room_seg&#39; contains the architectural features incuding the walls. &#39;pol_icon_seg&#39; contains the objects in the floorplan. . both of these can be used to identify the location of the walls and presence, count and locations of floor plan objects. . heatmaps, rooms, icons = split_prediction(prediction, img_size, split) polygons, types, room_polygons, room_types = get_polygons((heatmaps, rooms, icons), 0.2, [1, 2]) pol_room_seg, pol_icon_seg = polygons_to_image(polygons, types, room_polygons, room_types, height, width) plt.figure(figsize=(12,12)) ax = plt.subplot(1, 1, 1) ax.axis(&#39;off&#39;) rseg = ax.imshow(pol_room_seg, cmap=&#39;rooms&#39;, vmin=0, vmax=n_rooms-0.1) cbar = plt.colorbar(rseg, ticks=np.arange(n_rooms) + 0.5, fraction=0.046, pad=0.01) cbar.ax.set_yticklabels(room_classes, fontsize=20) plt.tight_layout() plt.show() plt.figure(figsize=(12,12)) ax = plt.subplot(1, 1, 1) ax.axis(&#39;off&#39;) iseg = ax.imshow(pol_icon_seg, cmap=&#39;icons&#39;, vmin=0, vmax=n_icons-0.1) cbar = plt.colorbar(iseg, ticks=np.arange(n_icons) + 0.5, fraction=0.046, pad=0.01) cbar.ax.set_yticklabels(icon_classes, fontsize=20) plt.tight_layout() plt.show() . Ground truth and prediction comparisons . fig = plt.figure(figsize=(26, 12)) grid = AxesGrid(fig, 111, nrows_ncols=(1, 2), axes_pad=0.05, cbar_mode=&#39;single&#39;, cbar_location=&#39;right&#39;, cbar_pad=0.1 ) images = [label_np[0], pol_room_seg] for i, ax in enumerate(grid): ax.set_axis_off() im = ax.imshow(images[i], cmap=&#39;rooms&#39;, vmin=0, vmax=n_rooms-0.1) cbar = ax.cax.colorbar(rseg, ticks=np.arange(n_rooms) + 0.5) cbar.ax.set_yticklabels(room_classes, fontsize=26) plt.show() . /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. del sys.path[0] . fig = plt.figure(figsize=(26, 12)) grid = AxesGrid(fig, 111, nrows_ncols=(1, 2), axes_pad=0.05, cbar_mode=&#39;single&#39;, cbar_location=&#39;right&#39;, cbar_pad=0.1 ) images = [label_np[1], pol_icon_seg] for i, ax in enumerate(grid): ax.set_axis_off() im = ax.imshow(images[i], cmap=&#39;icons&#39;, vmin=0, vmax=n_icons-0.1) cbar = ax.cax.colorbar(iseg, ticks=np.arange(n_icons) + 0.5) cbar.ax.set_yticklabels(icon_classes, fontsize=26) plt.show() . /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. from ipykernel import kernelapp as app .",
            "url": "https://tadbeer.github.io/unearth/2020/09/12/floor-plan-analysis.html",
            "relUrl": "/2020/09/12/floor-plan-analysis.html",
            "date": " • Sep 12, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "fastcore: An Underrated Python Library",
            "content": ". Background . I recently embarked on a journey to sharpen my python skills: I wanted to learn advanced patterns, idioms, and techniques. I started with reading books on advanced Python, however, the information didn&#39;t seem to stick without having somewhere to apply it. I also wanted the ability to ask questions from an expert while I was learning -- which is an arrangement that is hard to find! That&#39;s when it occurred to me: What if I could find an open source project that has fairly advanced python code and write documentation and tests? I made a bet that if I did this it would force me to learn everything very deeply, and the maintainers would be appreciative of my work and be willing to answer my questions. . And that&#39;s exactly what I did over the past month! I&#39;m pleased to report that it has been the most efficient learning experience I&#39;ve ever experienced. I&#39;ve discovered that writing documentation forced me to deeply understand not just what the code does but also why the code works the way it does, and to explore edge cases while writing tests. Most importantly, I was able to ask questions when I was stuck, and maintainers were willing to devote extra time knowing that their mentorship was in service of making their code more accessible! It turns out the library I choose, fastcore is some of the most fascinating Python I have ever encountered as its purpose and goals are fairly unique. . For the uninitiated, fastcore is a library on top of which many fast.ai projects are built on. Most importantly, fastcore extends the python programming language and strives to eliminate boilerplate and add useful functionality for common tasks. In this blog post, I&#39;m going to highlight some of my favorite tools that fastcore provides, rather than sharing what I learned about python. My goal is to pique your interest in this library, and hopefully motivate you to check out the documentation after you are done to learn more! . Why fastcore is interesting . Get exposed to ideas from other languages without leaving python: I’ve always heard that it is beneficial to learn other languages in order to become a better programmer. From a pragmatic point of view, I’ve found it difficult to learn other languages because I could never use them at work. Fastcore extends python to include patterns found in languages as diverse as Julia, Ruby and Haskell. Now that I understand these tools I am motivated to learn other languages. | You get a new set of pragmatic tools: fastcore includes utilities that will allow you to write more concise expressive code, and perhaps solve new problems. | Learn more about the Python programming language: Because fastcore extends the python programming language, many advanced concepts are exposed during the process. For the motivated, this is a great way to see how many of the internals of python work. | A whirlwind tour through fastcore . Here are some things you can do with fastcore that immediately caught my attention. . . Making **kwargs transparent . Whenever I see a function that has the argument **kwargs, I cringe a little. This is because it means the API is obfuscated and I have to read the source code to figure out what valid parameters might be. Consider the below example: . def baz(a, b=2, c =3, d=4): return a + b + c def foo(c, a, **kwargs): return c + baz(a, **kwargs) inspect.signature(foo) . &lt;Signature (c, a, **kwargs)&gt; . Without reading the source code, it might be hard for me to know that foo also accepts and additional parameters b and d. We can fix this with delegates: . def baz(a, b=2, c =3, d=4): return a + b + c @delegates(baz) # this decorator will pass down keyword arguments from baz def foo(c, a, **kwargs): return c + baz(a, **kwargs) inspect.signature(foo) . &lt;Signature (c, a, b=2, d=4)&gt; . You can customize the behavior of this decorator. For example, you can have your cake and eat it too by passing down your arguments and also keeping **kwargs: . @delegates(baz, keep=True) def foo(c, a, **kwargs): return c + baz(a, **kwargs) inspect.signature(foo) . &lt;Signature (c, a, b=2, d=4, **kwargs)&gt; . You can also exclude arguments. For example, we exclude argument d from delegation: . def basefoo(a, b=2, c =3, d=4): pass @delegates(basefoo, but= [&#39;d&#39;]) # exclude `d` def foo(c, a, **kwargs): pass inspect.signature(foo) . &lt;Signature (c, a, b=2)&gt; . You can also delegate between classes: . class BaseFoo: def __init__(self, e, c=2): pass @delegates()# since no argument was passsed here we delegate to the superclass class Foo(BaseFoo): def __init__(self, a, b=1, **kwargs): super().__init__(**kwargs) inspect.signature(Foo) . &lt;Signature (a, b=1, c=2)&gt; . For more information, read the docs on delegates. . . Avoid boilerplate when setting instance attributes . Have you ever wondered if it was possible to avoid the boilerplate involved with setting attributes in __init__? . class Test: def __init__(self, a, b ,c): self.a, self.b, self.c = a, b, c . Ouch! That was painful. Look at all the repeated variable names. Do I really have to repeat myself like this when defining a class? Not Anymore! Checkout store_attr: . class Test: def __init__(self, a, b, c): store_attr() t = Test(5,4,3) assert t.b == 4 . You can also exclude certain attributes: . class Test: def __init__(self, a, b, c): store_attr(but=[&#39;c&#39;]) t = Test(5,4,3) assert t.b == 4 assert not hasattr(t, &#39;c&#39;) . There are many more ways of customizing and using store_attr than I highlighted here. Check out the docs for more detail. . . Avoiding subclassing boilerplate . One thing I hate about python is the __super__().__init__() boilerplate associated with subclassing. For example: . class ParentClass: def __init__(self): self.some_attr = &#39;hello&#39; class ChildClass(ParentClass): def __init__(self): super().__init__() cc = ChildClass() assert cc.some_attr == &#39;hello&#39; # only accessible b/c you used super . We can avoid this boilerplate by using the metaclass PrePostInitMeta. We define a new class called NewParent that is a wrapper around the ParentClass: . class NewParent(ParentClass, metaclass=PrePostInitMeta): def __pre_init__(self, *args, **kwargs): super().__init__() class ChildClass(NewParent): def __init__(self):pass sc = ChildClass() assert sc.some_attr == &#39;hello&#39; . . Type Dispatch . Type dispatch, or Multiple dispatch, allows you to change the way a function behaves based upon the input types it receives. This is a prominent feature in some programming languages like Julia. For example, this is a conceptual example of how multiple dispatch works in Julia, returning different values depending on the input types of x and y: . collide_with(x::Asteroid, y::Asteroid) = ... # deal with asteroid hitting asteroid collide_with(x::Asteroid, y::Spaceship) = ... # deal with asteroid hitting spaceship collide_with(x::Spaceship, y::Asteroid) = ... # deal with spaceship hitting asteroid collide_with(x::Spaceship, y::Spaceship) = ... # deal with spaceship hitting spaceship . Type dispatch can be especially useful in data science, where you might allow different input types (i.e. Numpy arrays and Pandas dataframes) to a function that processes data. Type dispatch allows you to have a common API for functions that do similar tasks. . Unfortunately, Python does not support this out-of-the box. Fortunately, there is the @typedispatch decorator to the rescue. This decorator relies upon type hints in order to route inputs the correct version of the function: . @typedispatch def f(x:str, y:str): return f&#39;{x}{y}&#39; @typedispatch def f(x:np.ndarray): return x.sum() @typedispatch def f(x:int, y:int): return x+y . Below is a demonstration of type dispatch at work for the function f: . f(&#39;Hello &#39;, &#39;World!&#39;) . &#39;Hello World!&#39; . f(2,3) . 5 . f(np.array([5,5,5,5])) . 20 . There are limitations of this feature, as well as other ways of using this functionality that you can read about here. In the process of learning about typed dispatch, I also found a python library called multipledispatch made by Mathhew Rocklin (the creator of Dask). . After using this feature, I am now motivated to learn languages like Julia to discover what other paradigms I might be missing. . . A better version of functools.partial . functools.partial is a great utility that creates functions from other functions that lets you set default values. Lets take this function for example that filters a list to only contain values &gt;= val: . test_input = [1,2,3,4,5,6] def f(arr, val): &quot;Filter a list to remove any values that are less than val.&quot; return [x for x in arr if x &gt;= val] f(test_input, 3) . [3, 4, 5, 6] . You can create a new function out of this function using partial that sets the default value to 5: . filter5 = partial(f, val=5) filter5(test_input) . [5, 6] . One problem with partial is that it removes the original docstring and replaces it with a generic docstring: . filter5.__doc__ . &#39;partial(func, *args, **keywords) - new function with partial application n of the given arguments and keywords. n&#39; . fastcore.utils.partialler fixes this, and makes sure the docstring is retained such that the new API is transparent: . filter5 = partialler(f, val=5) filter5.__doc__ . &#39;Filter a list to remove any values that are less than val.&#39; . . Composition of functions . A technique that is pervasive in functional programming languages is function composition, whereby you chain a bunch of functions together to achieve some kind of result. This is especially useful when applying various data transformations. Consider a toy example where I have three functions: (1) Removes elements of a list less than 5 (from the prior section) (2) adds 2 to each number (3) sums all the numbers: . def add(arr, val): return [x + val for x in arr] def arrsum(arr): return sum(arr) # See the previous section on partialler add2 = partialler(add, val=2) transform = compose(filter5, add2, arrsum) transform([1,2,3,4,5,6]) . 15 . But why is this useful? You might me thinking, I can accomplish the same thing with: . arrsum(add2(filter5([1,2,3,4,5,6]))) . You are not wrong! However, composition gives you a convenient interface in case you want to do something like the following: . def fit(x, transforms:list): &quot;fit a model after performing transformations&quot; x = compose(*transforms)(x) y = [np.mean(x)] * len(x) # its a dumb model. Don&#39;t judge me return y # filters out elements &lt; 5, adds 2, then predicts the mean fit(x=[1,2,3,4,5,6], transforms=[filter5, add2]) . [7.5, 7.5] . For more information about compose, read the docs. . . A more useful __repr__ . In python, __repr__ helps you get information about an object for logging and debugging. Below is what you get by default when you define a new class. (Note: we are using store_attr, which was discussed earlier). . class Test: def __init__(self, a, b=2, c=3): store_attr() # `store_attr` was discussed previously Test(1) . &lt;__main__.Test at 0x7fe0ab662790&gt; . We can use basic_repr to quickly give us a more sensible default: . class Test: def __init__(self, a, b=2, c=3): store_attr() __repr__ = basic_repr(&#39;a,b,c&#39;) Test(2) . Test(a=2, b=2, c=3) . . Monkey Patching With A Decorator . It can be convenient to monkey patch with a decorator, which is especially helpful when you want to patch an external library you are importing. We can use the decorator @patch from fastcore.foundation along with type hints like so: . class MyClass(int): pass @patch def func(self:MyClass, a): return self+a mc = MyClass(3) . Now, MyClass has an additional method named func: . mc.func(10) . 13 . Still not convinced? I&#39;ll show you another example of this kind of patching in the next section. . . A better pathlib.Path . When you see these extensions to pathlib.path you won&#39;t ever use vanilla pathlib again! A number of additional methods have been added to pathlib, such as: . Path.readlines: same as with open(&#39;somefile&#39;, &#39;r&#39;) as f: f.readlines() | Path.read: same as with open(&#39;somefile&#39;, &#39;r&#39;) as f: f.read() | Path.save: saves file as pickle | Path.load: loads pickle file | Path.ls: shows the contents of the path as a list. | etc. | . Read more about this here. Here is a demonstration of ls: . from pathlib import Path p = Path(&#39;../_notebooks&#39;) p.ls() # you don&#39;t get this with vanilla Pathlib.Path!! . (#21) [Path(&#39;../_notebooks/gpt2_simple_mask.jpg&#39;),Path(&#39;../_notebooks/bert_mac_small.jpg&#39;),Path(&#39;../_notebooks/causal_with_prefix.jpg&#39;),Path(&#39;../_notebooks/.DS_Store&#39;),Path(&#39;../_notebooks/2020-03-07-How_to_Create_an_Automatic_Code_Comment_Generator_using_Deep_Learning.ipynb&#39;),Path(&#39;../_notebooks/2020-09-01-fastcore.ipynb&#39;),Path(&#39;../_notebooks/2020-03-07-Syntax-Highlighting.ipynb&#39;),Path(&#39;../_notebooks/2020-03-06-bart.ipynb&#39;),Path(&#39;../_notebooks/README.md&#39;),Path(&#39;../_notebooks/2020-05-01-TrainDonkeyCar.ipynb&#39;)...] . Wait! What&#39;s going on here? We just imported pathlib.Path - why are we getting this new functionality? Thats because we imported the fastcore.foundation module, which patches this module via the @patch decorator discussed earlier. Just to drive the point home on why the @patch decorator is useful, I&#39;ll go ahead and add another method to Path right now: . @patch def fun(self:Path): return &quot;This is fun!&quot; p.fun() . &#39;This is fun!&#39; . That is magical, right? I know! That&#39;s why I&#39;m writing about it! . . An Even More Concise Way To Create Lambdas . Self, with an uppercase S, is an even more concise way to create lambdas that are calling methods on an object. For example, let&#39;s create a lambda for taking the sum of a Numpy array: . arr=np.array([5,4,3,2,1]) f = lambda a: a.sum() assert f(arr) == 15 . You can use Self in the same way: . f = Self.sum() assert f(arr) == 15 . Let&#39;s create a lambda that does a groupby and max of a Pandas dataframe: . import pandas as pd df=pd.DataFrame({&#39;Some Column&#39;: [&#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;b&#39;, ], &#39;Another Column&#39;: [5, 7, 50, 70]}) f = Self.groupby(&#39;Some Column&#39;).mean() f(df) . Another Column . Some Column . a 6 | . b 60 | . Read more about Self in the docs). . . Notebook Functions . These are simple but handy, and allow you to know whether or not code is executing in a Jupyter Notebook, Colab, or an Ipython Shell: . in_notebook(), in_colab(), in_ipython() . (True, False, True) . This is useful if you are displaying certain types of visualizations, progress bars or animations in your code that you may want to modify or toggle depending on the environment. . . A Drop-In Replacement For List . You might be pretty happy with Python&#39;s list. This is one of those situations that you don&#39;t know you needed a better list until someone showed one to you. Enter L, a list like object with many extra goodies. . The best way I can describe L is to pretend that list and numpy had a pretty baby: . define a list (check out the nice __repr__ that shows the length of the list!) . L(1,2,3) . (#3) [1,2,3] . Shuffle a list: . p = L.range(20).shuffle() p . (#20) [2,0,18,6,15,17,14,8,12,1...] . Index into a list: . p[2,4,6] . (#3) [18,15,14] . L has sensible defaults, for example appending an element to a list: . 1 + L(2,3,4) . (#4) [1,2,3,4] . There is much more L has to offer. Read the docs to learn more. . But Wait ... There&#39;s More! . There are more things I would like to show you about fastcore, but there is no way they would reasonably fit into a blog post. Here is a list of some of my favorite things that I didn&#39;t demo in this blog post: . Utilities . The Utilites section contain many shortcuts to perform common tasks or provide an additional interface to what standard python provides. . mk_class: quickly add a bunch of attributes to a class | wrap_class: add new methods to a class with a simple decorator | groupby: similar to Scala&#39;s groupby | merge: merge dicts | fasttuple: a tuple on steroids | Infinite Lists: useful for padding and testing | chunked: for batching and organizing stuff | . Multiprocessing . The Multiprocessing section extends python&#39;s multiprocessing library by offering features like: . progress bars | ability to pause to mitigate race conditions with external services | processing things in batches on each worker, ex: if you have a vectorized operation to perform in chunks | . Functional Programming . The functional programming section is my favorite part of this library. . maps: a map that also composes functions | mapped: A more robust map | using_attr: compose a function that operates on an attribute | . Transforms . Transforms is a collection of utilities for creating data transformations and associated pipelines. These transformation utilities build upon many of the building blocks discussed in this blog post. . Further Reading . It should be noted that you should read the main page of the docs first, followed by the section on tests to fully understand the documentation. . The fastcore documentation site. | The fastcore GitHub repo. | Blog post on delegation. | . Shameless plug: fastpages . This blog post was written entirely in a Jupyter Notebook, which GitHub automatically converted into to a blog post! Sound interesting? Check out fastpages. .",
            "url": "https://tadbeer.github.io/unearth/fastcore/",
            "relUrl": "/fastcore/",
            "date": " • Sep 1, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://tadbeer.github.io/unearth/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://tadbeer.github.io/unearth/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://tadbeer.github.io/unearth/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://tadbeer.github.io/unearth/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}